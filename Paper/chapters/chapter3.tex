\chapter{Architecture and implementation}

The application is divided into three parts:
	\begin{itemize}
		\addtolength{\itemindent}{1cm}
		\item The Neuronal Network Engine
		\item The User Input Handling and Processing
		\item The Application-User interaction via the GUI
	\end{itemize}

We will continue this chapter by entering into the details of each of the aforementioned component.

\section{The Neuronal Network Engine}

The the Neural Network Engine was developed using the Neural Network Framework which we implemented from scratch.
The main application problem can be reduced to a binary classification problem ( the engine has to predict if a given
input falls into the category Piano or Other), thus we choosen the following architecture:


\begin{figure}[H]
	\centering
	\includegraphics[width = 1.3in]{images/summary.png}
	\caption{A summary of the model architecture}
\label{model_arch}
\end{figure}

The Neural Network Engine consists of a model, which is a binary serialized file containing the weights and biases
of the trainable layers from the figure \ref{model_arch}.

The model values and its performance are the result of the training process, which consisted of five epochs over 33602
inputs values (one second wav audio snippets), presented to the model in the form of \textit{batches} provided
by the custom \textit{Data generator}, with each batch containing 32 samples.

Initially we approached the problem without using Convolutional Operations, but after testing numerous configurations
the results were below satisfying (with the loss stagnating at a value of about 0.5 ), as ilustrated in the figure below.


\begin{figure}[H]
	\centering
	\includegraphics[width = 5.5in]{images/badmetricspng.png}
	\caption{Model loss before adding Convolutional Operations to the Model}
\label{bad_metrics}
\end{figure}


By incorporating the Convolutional Operations and Layers into the Neural Network Framework, the model accuracy as well
as the loss improved at a visible rate, as shown below.


\begin{figure}[H]
	\centering
	\includegraphics[width = 5.5in]{images/metrics.png}
	\caption{The model loss after incorporating Convolutional Layers}
\label{good_metrics}
\end{figure}


The general flow of the data in the Neural Network Framework is based on the forward-backward propagation principle,
specific to the \textit{Convolutional Neural Network} architecture.
Each of the trainable model's layers have the following methods:

\begin{enumerate}
	\item :function:forward(inputs): A method which takes the previous layer output as the parameter(inputs)
	and perform the specific operations, thus performing the forward data processing.
	\item :function:backward(derivated values): A method which takes the previous layer output, which consists
	of the gradient of the forward propagation end result(derivated values), performing the inverse
	computations in regards to the forward method, and then propagating the end result to the next layer.
	\item :parameter:output: A \textit{ndarray} where the \textit{forward} function computations are stored.
	\item :parameter:derivated input: A \textit{ndarray} where the \textit{backward} function computations are stored.

\end{enumerate}

The following diagram ilustrates the forward-backward propagation of the Neural Network Model.

\begin{figure}[H]
	\centering
	\includegraphics[width = 5.5in]{images/fwbw.png}
	\caption{Data flow throughout the model (image source \cite{fwbw})}
\label{data_flow}
\end{figure}


The effective learning process is facilitated by the Optimizer Function, which adjusts the weights and biases of each individual
layer.

At the end of each iteration the model has to classify unseen data ( the \textit{validation data}), and based on the results of
the classification, the model \textit{metrics} are computed, in the form of loss (computed with \textit{Categorical CrossEntropy})
and accuracy (computed with \textit{CategoricalAccuracy}).


\section{User Input Handling and Processing}

The modus operandi of the input handling and processing pipeline is presented in the following diagram.

\begin{figure}[H]
	\centering
	\includegraphics[width = 6.5in]{images/datapipe.png}
	\caption{User input handling pipeline}
\label{mo}
\end{figure}

The steps performed in order process the user input are as follows:
\begin{enumerate}

	\item Validating the user input : Checking if the input link inserted by the user is a valid YouTube link to
	either a video or a playlist.
	\item Downloading the video : Saving and converting the video at the specified link in a temporary folder.
		The \textit{youtube-dl} utilitary facilitates this step by downloading the file using
	a list of specified configuration parameters such as audio quality and the output format. After this step,
	we will have obtained an audio file of format wav.
	\item Audio file cleaning: Given the reason that the model was trained on 1 second snippets of audio files of sample rate of 16000,
		the following operations are necessary to be performed to the audio file in order for it to be compatible with the Neural Network Engine:
		\begin{itemize}
			\item Downsampling the wav file to mono: Reducing the number of channels of the file to
			mono with the function \textit{to mono} from \textit{librosa}.
			\item Cleaning the wav file by sound envelope.
			\begin{figure}[H]
				\centering
				\includegraphics{images/soundenvelope.png}
				\caption{Sound envelope example (Source \cite{sev})}
			\label{se}
			\end{figure}

	The sound envelope (presented in the figure \ref{se}), represents the changes in audio frequency over a period
	of time. The \textit{split wav by sound envelope} function computes a \textit{filtered mask} of the audio file
	by comparing each value of the sound envelope to a given threshold, thus eliminating the audio noise(such as
	crowd cheering and silence), keeping only the relevant audio information.

			\item Splitting the masked audio file: After the first two steps of the audio processing,
	the audio file has to be splitted into 1 second samples and converted to a sample rate of 16000.
		\end{itemize}

	\item Extracting a number of random sound samples: In order to offer an accurate prediction and reduce the
	time cost required by the Neural Network Engine, we randomly extract a number of samples from the splitted audio
	file.
\item Loading the random sound samples into the model: The Neural Network Engine has also the \textit{inference}
	functionality. The inference/prediction is performed by transforming the input data (transformation performed
	by the input layer), then performing the forward-backward data propagation once.
	The transformations applied by the input layer are:
	\begin{itemize}

		\item Short Time Fourier Transformation
		Short Time Fourier Transformation is a mathematical transformation technique used for
		decomposing a function relative to its spatial and temporal dependencies. Since the audio signal is
		composed of sound wave which only ilustrate the amplitude of
		a recording, the Fourier transform allows for the creation of an illustration of a frequency
		over time,called spectrum. \cite{ft}

			\begin{figure}[H]
				\centering
				\includegraphics[width = 4.5in]{images/ft.png}
				\caption{Fourier transformation (Source \cite{ft})}
			\label{ft}
			\end{figure}


		\item MEL Filterbank transformation

			The \textit{MEL} scale is a reprezentation of the sounds that can be heard and
			distinguished by the human ear. The \textit{MEL spectogram} is a graphical representation
			of the sound variations and intensities of the a given audio sample. With the
			\textit{MEL Filterbank transformation} we effectively represent the relevant information
			of the input data, thus transforming the problem from an audio classification
			into an image classification suited for the Convolutional Neuronal Network.

			\begin{figure}[H]
				\centering
				\includegraphics[width = 5.5in]{images/mel.png}
				\caption{MEL Spectogram example}
			\label{ms}
			\end{figure}


	\end{itemize}
	The output of the transformation is a \textit{ndarray} containing the MEL spectogram
	of the input sample which represents the neural network model's input.\\
	The inference output is an array containing floating point numbers which represent the confidence
	value of the model prediction.\\
	The predicted label is computed by extracting the \textit{argmax}(the index
	of the element with the biggest value), then mapping it to the specific class name.


	\item Interpreting the result and returning the final prediction: The output label is stored for each prediction
	extracted from the random samples batch. The final label is computed by extracting the prediction
	which was suggested most often.

\end{enumerate}
\section{The Application-User Interaction}
	The application provides a minimalistic Graphic User Interface which offers the end user the means for
	classifying an YouTube song, as well as visualise the specific 3D Animation depending on the model prediction.
	The following figure illustrate some of the application states.


			\begin{figure}[H]
				\centering
				\includegraphics[width = 4.5in]{images/basic_interface.png}
				\caption{The Graphic User Interface at the start of the application}
			\label{guis}
			\end{figure}

			\begin{figure}[H]
				\centering
				\includegraphics[width = 4.5in]{images/piano.png}
				\caption{The Graphic User Interface after predicting a song as a piano song.}
			\label{guip}
			\end{figure}

			\begin{figure}[H]
				\centering
				\includegraphics[width = 4.5in]{images/other.png}
				\caption{The Graphic User Interface after classifying a song as other.}
			\label{guio}
			\end{figure}
