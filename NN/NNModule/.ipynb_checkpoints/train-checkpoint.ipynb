{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0,  acc: 0.250,  loss: 0.764 ( + data_loss: 0.764,reg_loss: 0.000),lr: 0.001 \n",
      "\n",
      "step: 5,  acc: 0.562,  loss: 6.650 ( + data_loss: 6.650,reg_loss: 0.000),lr: 0.0009997500624843788 \n",
      "\n",
      "step: 10,  acc: 0.562,  loss: 0.885 ( + data_loss: 0.885,reg_loss: 0.000),lr: 0.0009995002498750624 \n",
      "\n",
      "step: 15,  acc: 0.500,  loss: 0.695 ( + data_loss: 0.695,reg_loss: 0.000),lr: 0.0009992505620784412 \n",
      "\n",
      "step: 20,  acc: 0.656,  loss: 0.578 ( + data_loss: 0.578,reg_loss: 0.000),lr: 0.0009990009990009992 \n",
      "\n",
      "step: 25,  acc: 0.531,  loss: 0.627 ( + data_loss: 0.627,reg_loss: 0.000),lr: 0.0009987515605493133 \n",
      "\n",
      "step: 30,  acc: 0.719,  loss: 0.616 ( + data_loss: 0.616,reg_loss: 0.000),lr: 0.0009985022466300548 \n",
      "\n",
      "step: 35,  acc: 0.594,  loss: 0.642 ( + data_loss: 0.642,reg_loss: 0.000),lr: 0.0009982530571499876 \n",
      "\n",
      "step: 40,  acc: 0.719,  loss: 0.678 ( + data_loss: 0.678,reg_loss: 0.000),lr: 0.000998003992015968 \n",
      "\n",
      "step: 45,  acc: 0.312,  loss: 0.694 ( + data_loss: 0.694,reg_loss: 0.000),lr: 0.0009977550511349464 \n",
      "\n",
      "step: 50,  acc: 0.438,  loss: 0.703 ( + data_loss: 0.703,reg_loss: 0.000),lr: 0.0009975062344139652 \n",
      "\n",
      "step: 55,  acc: 0.062,  loss: 0.708 ( + data_loss: 0.708,reg_loss: 0.000),lr: 0.0009972575417601596 \n",
      "\n",
      "step: 60,  acc: 0.594,  loss: 0.693 ( + data_loss: 0.693,reg_loss: 0.000),lr: 0.0009970089730807579 \n",
      "\n",
      "step: 65,  acc: 0.531,  loss: 0.671 ( + data_loss: 0.671,reg_loss: 0.000),lr: 0.00099676052828308 \n",
      "\n",
      "step: 70,  acc: 0.625,  loss: 0.690 ( + data_loss: 0.690,reg_loss: 0.000),lr: 0.000996512207274539 \n",
      "\n",
      "step: 75,  acc: 0.469,  loss: 0.693 ( + data_loss: 0.693,reg_loss: 0.000),lr: 0.0009962640099626403 \n",
      "\n",
      "step: 80,  acc: 0.500,  loss: 0.693 ( + data_loss: 0.693,reg_loss: 0.000),lr: 0.00099601593625498 \n",
      "\n",
      "step: 85,  acc: 0.625,  loss: 0.688 ( + data_loss: 0.688,reg_loss: 0.000),lr: 0.0009957679860592482 \n",
      "\n",
      "step: 90,  acc: 0.531,  loss: 0.656 ( + data_loss: 0.656,reg_loss: 0.000),lr: 0.0009955201592832257 \n",
      "\n",
      "step: 95,  acc: 0.594,  loss: 0.488 ( + data_loss: 0.488,reg_loss: 0.000),lr: 0.0009952724558347848 \n",
      "\n",
      "step: 100,  acc: 0.750,  loss: 0.683 ( + data_loss: 0.683,reg_loss: 0.000),lr: 0.0009950248756218907 \n",
      "\n",
      "step: 105,  acc: 0.562,  loss: 0.564 ( + data_loss: 0.564,reg_loss: 0.000),lr: 0.000994777418552599 \n",
      "\n",
      "step: 110,  acc: 0.500,  loss: 0.641 ( + data_loss: 0.641,reg_loss: 0.000),lr: 0.000994530084535057 \n",
      "\n",
      "step: 115,  acc: 0.781,  loss: 0.635 ( + data_loss: 0.635,reg_loss: 0.000),lr: 0.0009942828734775045 \n",
      "\n",
      "step: 120,  acc: 0.562,  loss: 0.542 ( + data_loss: 0.542,reg_loss: 0.000),lr: 0.0009940357852882705 \n",
      "\n",
      "step: 125,  acc: 0.688,  loss: 0.602 ( + data_loss: 0.602,reg_loss: 0.000),lr: 0.0009937888198757762 \n",
      "\n",
      "step: 130,  acc: 0.469,  loss: 0.667 ( + data_loss: 0.667,reg_loss: 0.000),lr: 0.0009935419771485345 \n",
      "\n",
      "step: 135,  acc: 0.781,  loss: 0.480 ( + data_loss: 0.480,reg_loss: 0.000),lr: 0.0009932952570151478 \n",
      "\n",
      "step: 140,  acc: 0.906,  loss: 0.459 ( + data_loss: 0.459,reg_loss: 0.000),lr: 0.00099304865938431 \n",
      "\n",
      "step: 145,  acc: 0.875,  loss: 0.647 ( + data_loss: 0.647,reg_loss: 0.000),lr: 0.0009928021841648052 \n",
      "\n",
      "step: 150,  acc: 0.594,  loss: 0.641 ( + data_loss: 0.641,reg_loss: 0.000),lr: 0.0009925558312655087 \n",
      "\n",
      "step: 155,  acc: 0.719,  loss: 0.576 ( + data_loss: 0.576,reg_loss: 0.000),lr: 0.000992309600595386 \n",
      "\n",
      "step: 160,  acc: 0.594,  loss: 0.634 ( + data_loss: 0.634,reg_loss: 0.000),lr: 0.000992063492063492 \n",
      "\n",
      "step: 165,  acc: 0.594,  loss: 0.688 ( + data_loss: 0.688,reg_loss: 0.000),lr: 0.0009918175055789735 \n",
      "\n",
      "step: 170,  acc: 0.500,  loss: 0.685 ( + data_loss: 0.685,reg_loss: 0.000),lr: 0.000991571641051066 \n",
      "\n",
      "step: 175,  acc: 0.531,  loss: 0.648 ( + data_loss: 0.648,reg_loss: 0.000),lr: 0.0009913258983890955 \n",
      "\n",
      "step: 180,  acc: 0.625,  loss: 0.676 ( + data_loss: 0.676,reg_loss: 0.000),lr: 0.000991080277502478 \n",
      "\n",
      "step: 185,  acc: 0.844,  loss: 0.506 ( + data_loss: 0.506,reg_loss: 0.000),lr: 0.0009908347783007185 \n",
      "\n",
      "step: 190,  acc: 0.750,  loss: 0.640 ( + data_loss: 0.640,reg_loss: 0.000),lr: 0.0009905894006934125 \n",
      "\n",
      "step: 195,  acc: 0.938,  loss: 0.484 ( + data_loss: 0.484,reg_loss: 0.000),lr: 0.0009903441445902451 \n",
      "\n",
      "step: 200,  acc: 0.844,  loss: 0.524 ( + data_loss: 0.524,reg_loss: 0.000),lr: 0.0009900990099009901 \n",
      "\n",
      "step: 205,  acc: 0.594,  loss: 0.592 ( + data_loss: 0.592,reg_loss: 0.000),lr: 0.000989853996535511 \n",
      "\n",
      "step: 210,  acc: 0.750,  loss: 0.572 ( + data_loss: 0.572,reg_loss: 0.000),lr: 0.0009896091044037606 \n",
      "\n",
      "step: 215,  acc: 0.469,  loss: 0.750 ( + data_loss: 0.750,reg_loss: 0.000),lr: 0.0009893643334157804 \n",
      "\n",
      "step: 220,  acc: 0.500,  loss: 0.848 ( + data_loss: 0.848,reg_loss: 0.000),lr: 0.0009891196834817015 \n",
      "\n",
      "step: 225,  acc: 0.844,  loss: 0.519 ( + data_loss: 0.519,reg_loss: 0.000),lr: 0.000988875154511743 \n",
      "\n",
      "step: 230,  acc: 0.438,  loss: 0.696 ( + data_loss: 0.696,reg_loss: 0.000),lr: 0.0009886307464162135 \n",
      "\n",
      "step: 235,  acc: 0.750,  loss: 0.774 ( + data_loss: 0.774,reg_loss: 0.000),lr: 0.0009883864591055103 \n",
      "\n",
      "step: 240,  acc: 0.812,  loss: 0.544 ( + data_loss: 0.544,reg_loss: 0.000),lr: 0.0009881422924901185 \n",
      "\n",
      "step: 245,  acc: 0.844,  loss: 0.326 ( + data_loss: 0.326,reg_loss: 0.000),lr: 0.0009878982464806125 \n",
      "\n",
      "step: 250,  acc: 0.531,  loss: 0.637 ( + data_loss: 0.637,reg_loss: 0.000),lr: 0.0009876543209876543 \n",
      "\n",
      "step: 255,  acc: 0.812,  loss: 0.814 ( + data_loss: 0.814,reg_loss: 0.000),lr: 0.0009874105159219946 \n",
      "\n",
      "step: 260,  acc: 0.625,  loss: 0.882 ( + data_loss: 0.882,reg_loss: 0.000),lr: 0.000987166831194472 \n",
      "\n",
      "step: 265,  acc: 0.875,  loss: 0.574 ( + data_loss: 0.574,reg_loss: 0.000),lr: 0.0009869232667160128 \n",
      "\n",
      "step: 270,  acc: 0.750,  loss: 0.577 ( + data_loss: 0.577,reg_loss: 0.000),lr: 0.0009866798223976318 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# o sa am nevoie si eu de rahatu ala cu training(argumentu nefolosit)\n",
    "# pentru maaxpooling si conv2d metoda e ca primesc batchu la forma (N , C , W, H) si atributu input shape ia shape[1:], dar trebuie sa\n",
    "# greseala e la input batch handling si faza cu channels first\n",
    "# si faza cu training loop, dupa ce se face forward si backprop trebuie reshapeuit arrayul(in model training loop)\n",
    "# am in vedere ca inputul primit dinainte in retea sa fie de forma asta sau sa i se faca reshape .\n",
    "from Layers.InputLayer import InputLayer\n",
    "from ModelClass.Model import Model\n",
    "from Metrics.CategoricalAccuracy import CategoricalAccuracy\n",
    "from Metrics.CategoricalCrossentropy import CategoricalCrossentropy\n",
    "from Optimizers.OptimizerAdam import OptimizerAdam\n",
    "from Activations.ActivationReLu import ActivationReLu\n",
    "from Activations.ActivationSoftmax import ActivationSoftmax\n",
    "from Layers.DropoutLayer import DropoutLayer\n",
    "from Layers.DenseLayer import DenseLayer\n",
    "from Layers.BatchNormalizationLayer import BatchNormalization\n",
    "from Layers.FlattenLayer import Flatten\n",
    "from Layers.MaxPooling2DLayer import MaxPooling2D\n",
    "from Layers.Conv2DLayer import Conv2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ModelClass.DataGenerator import DataGenerator\n",
    "from glob import glob                \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def create_dataset(path):\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(path), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n",
    "    classes = os.listdir(path)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.1,\n",
    "                                                                  random_state=0)\n",
    "    return wav_train, wav_val, label_train, label_val\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path = './clean/piano'\n",
    "    create_dataset(path)\n",
    "    sr = 16000\n",
    "    dt = 1.0\n",
    "    nr_classes = 2\n",
    "    batch_size = 32\n",
    "    wav_train, wav_val, label_train, label_val = create_dataset(path)\n",
    "\n",
    "    # Creating the data generators\n",
    "    tg = DataGenerator(wav_train, label_train, sr, dt,\n",
    "                       nr_classes, batch_size=batch_size)\n",
    "    vg = DataGenerator(wav_val, label_val, sr, dt,\n",
    "                       nr_classes, batch_size=batch_size)\n",
    "\n",
    "    # il = InputLayer()\n",
    "    # il.forward(tg.__getitem__(0)[0])\n",
    "    # print(il.output.shape)\n",
    "\n",
    "    model = Model()\n",
    "    # Add layers\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(8, (7, 7)))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(MaxPooling2D(pool_shape=(2, 2), padding='same'))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(Conv2D(16, (5, 5)))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(MaxPooling2D(pool_shape=(2, 2), padding='same'))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(Conv2D(16, (3, 3)))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(MaxPooling2D(pool_shape=(2, 2), padding='same'))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(MaxPooling2D(pool_shape=(2, 2), padding='same'))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(Flatten())\n",
    "    model.add(DropoutLayer(0.2))\n",
    "    model.add(DenseLayer(131072, 64))\n",
    "    model.add(ActivationReLu())\n",
    "    model.add(DenseLayer(64, 2))\n",
    "    model.add(ActivationSoftmax())\n",
    "\n",
    "    # Set loss, optimizer and accuracy objects\n",
    "    model.set(\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        optimizer=OptimizerAdam(decay=5e-5),\n",
    "        accuracy=CategoricalAccuracy()\n",
    "    )\n",
    "    # Finalize the model\n",
    "    model.finalize()\n",
    "    # Train the model\n",
    "    model.train(train_generator=tg, validation_generator=vg,\n",
    "                epochs=2\n",
    "                , batch_size=batch_size, print_every=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('audio_classification.h5')\n",
    " #   Read an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     dataset_labels={0:'Other',\n",
    "#                     1:'Piano'}\n",
    "#     audio_file = wavfile.read('./output_0.wav')\n",
    "\n",
    "#     X = np.empty((1, int(16000*1.0), 1),dtype=np.float32)\n",
    "\n",
    "#     Y = np.empty((1, 2), dtype=np.float32)\n",
    "#     X[0, ] = audio_file[1].reshape(-1, 1)\n",
    "    \n",
    "#     model = Model.load('audio_classification.h5')\n",
    "#     confidences = model.predict(X)\n",
    "#     # Get prediction instead of confidence levels\n",
    "#     predictions = model.output_layer_activation.predictions(confidences)\n",
    "#     print(confidences)\n",
    "#     # Get label name from label index\n",
    "#     prediction = dataset_labels[predictions[0]]\n",
    "#     print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
